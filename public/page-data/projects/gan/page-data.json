{"componentChunkName":"component---src-templates-blog-post-js","path":"/projects/gan/","webpackCompilationHash":"","result":{"data":{"markdownRemark":{"html":"<p>One of the biggest challenges of deep learning is figuring out how to use artificial intelligence to generate data like picture, video, text, and sound. In 2010, Ian Goodfellow published a paper popularizing a technique knowing as generative adversarial networks (GAN). To explain how it works, we can think of the technique as 2 people, a forger and an art detective, competing against each other. The forger will try to created forged paintings, and the detective will try to spot the fakes. As the detective spots more and more fakes, she will get better at finding the forged works. Likewise, as the forger sees how the detective is spotting his fake, he will get better and better at making the forgeries. This will go back and forth until us normal humans won’t be able to tell the difference between the reals and fakes. </p>\n<p>In technical terms, it uses a convolutional neural network, called a discriminator network, to identify fakes and a dense neural network to create the images. Both networks start out untrained, and the convolutional network is trained every epoch on a labeled real and fake image. For the generative network, the output of the discriminator on a fake image is set the target to one (as if it was a real image) and the error is passed back through the discriminator and into the generative network to be used as error values for backpropagation</p>\n<p>These networks can produce incredibly realistic images such as the images produced by researchers at Nvidia. This technique is a standard method to generate realistic looking data, so it is a given that any hopeful AI engineer should know this.</p>\n<p>Due to its incredible power, I used Diego Mosquera’s tutorial on constructing a GAN to guide me through the process. The GAN I created uses the famous MNIST data set of handwritten numbers as a reference to generate images. This is a small subset of the training examples\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 480px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ffdd48af507af250efffc9124476bd6e/98431/mnistExample.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHkKUakh//EABcQAAMBAAAAAAAAAAAAAAAAAAARIQH/2gAIAQEAAQUCjig6zNw//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFhABAQEAAAAAAAAAAAAAAAAAMRAg/9oACAEBAAY/AiGP/8QAHRAAAgAHAQAAAAAAAAAAAAAAABEBIUFhoeHwsf/aAAgBAQABPyGEznhYxo4WhGERXI//2gAMAwEAAgADAAAAENPP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAIBAAAQMEAgMAAAAAAAAAAAAAAQARITFBYZFRcYHh8P/aAAgBAQABPxAAEYQ0IfJuzCMZMdOEmLR9RUEa9Jiaj3GOl//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"mnistExample\"\n        title=\"mnistExample\"\n        src=\"/static/ffdd48af507af250efffc9124476bd6e/98431/mnistExample.jpg\"\n        srcset=\"/static/ffdd48af507af250efffc9124476bd6e/8ee9c/mnistExample.jpg 148w,\n/static/ffdd48af507af250efffc9124476bd6e/ebbe7/mnistExample.jpg 295w,\n/static/ffdd48af507af250efffc9124476bd6e/98431/mnistExample.jpg 480w\"\n        sizes=\"(max-width: 480px) 100vw, 480px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>This was the network’s first try.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/5c76240b0d47ccf277b59cc8802658a0/7bd40/gan_init.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 25.531914893617024%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA1UlEQVQY0yWOx6qDQABF/UhXEewKUeztxYaK2DFB8H9zeJnFwJ255QiPxyMIAl3XwzCMokiW5SzLkEVRpGlq23ZVVUjP80zTRL5eLyQ3TsFxnGVZSM7z3HUdpn3fkyR5v9/btpG879v3fTx//+e6LsyfzwePIEkSeUVR4jh2Xff5fOZ5zkhZlrzQxQgSCsuyDMMgqWla27aqqgqiKP6w0aDiPs+T2DAM4zhS1/c9tPySJ0Y1LXyBI9BKhnEgm6b5cYK3riuxuq6P42BtmiY4meGFG3h6v6SYh9+eJU0TAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"GANinit\"\n        title=\"GANinit\"\n        src=\"/static/5c76240b0d47ccf277b59cc8802658a0/b9e4f/gan_init.png\"\n        srcset=\"/static/5c76240b0d47ccf277b59cc8802658a0/cf440/gan_init.png 148w,\n/static/5c76240b0d47ccf277b59cc8802658a0/d2d38/gan_init.png 295w,\n/static/5c76240b0d47ccf277b59cc8802658a0/b9e4f/gan_init.png 590w,\n/static/5c76240b0d47ccf277b59cc8802658a0/f9b6a/gan_init.png 885w,\n/static/5c76240b0d47ccf277b59cc8802658a0/7bd40/gan_init.png 893w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Once training was complete the network was performing remarkably well.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/1b3e87ef7dc99df08ceb9a3b6763add0/7bd40/gan_final.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 25.531914893617024%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA5ElEQVQY0z1PS8tFUBQ93pFH5P2mhKGSUkbKRCmZ3QxuiYGR/z+760t9k9NeZ6/XJoQQx3HwxnEcRREGXdfxhmFo2zbLsk3T0DSNLf5VVR3HkeO4IAgsyyKKotR1Dfa6rkVRgP1abNuWpqnnefu+UxQFaJrmMAzf7xfwOI48zwnDMPCDt+/7PM9DJkkS1qBixuotkiTJfx0MiIWQoMA8zxAjGTmapj3PYxhG13Wg4qLzPAVBuK6rLMssyz6fD8T3faPFn8dbG52rqmrbFlcBgiqKouu6fd8DTtP0eiFJluVlWUD+ARd9JKaOdVpvAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"GANfinal\"\n        title=\"GANfinal\"\n        src=\"/static/1b3e87ef7dc99df08ceb9a3b6763add0/b9e4f/gan_final.png\"\n        srcset=\"/static/1b3e87ef7dc99df08ceb9a3b6763add0/cf440/gan_final.png 148w,\n/static/1b3e87ef7dc99df08ceb9a3b6763add0/d2d38/gan_final.png 295w,\n/static/1b3e87ef7dc99df08ceb9a3b6763add0/b9e4f/gan_final.png 590w,\n/static/1b3e87ef7dc99df08ceb9a3b6763add0/f9b6a/gan_final.png 885w,\n/static/1b3e87ef7dc99df08ceb9a3b6763add0/7bd40/gan_final.png 893w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>As you can see, the generated numbers do closely resemble the data set and with a graphics card, I could run a larger network that could even replicate the data even further. However, I am very happy with my progress as the GAN learned to create realistic hand-drawn numbers. I plan on trying to generate faces once I upgrade my hardware. </p>\n<p><img src=\"/cc9a71f6e5ecbc5db0af6326d118be6b/GANgif2.gif\" alt=\"GANgif\"></p>","frontmatter":{"title":"It GAN do it! (Generative Adversarial Networks)"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/projects/gan/"}}}